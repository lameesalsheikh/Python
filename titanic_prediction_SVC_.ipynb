{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6wBZkxh_58D",
        "outputId": "54c84244-e4e2-483d-dbc7-8d3090a0fce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8044692737430168\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84       105\n",
            "           1       0.83      0.66      0.74        74\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.81      0.78      0.79       179\n",
            "weighted avg       0.81      0.80      0.80       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Titanic dataset\n",
        "titanic_data = pd.read_csv('/content/titanic_train.csv')\n",
        "\n",
        "# Drop columns that may not contribute to the model or require additional processing\n",
        "titanic_data = titanic_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numeric and categorical features\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "\n",
        "# Create transformers for numeric and categorical features\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer to apply transformers to different feature sets\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create an SVC model\n",
        "svc_model = SVC()\n",
        "\n",
        "# Create a pipeline with preprocessing and SVC\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', svc_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained pipeline\n",
        "joblib.dump(pipeline, 'titanic_svc_model.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbeOAV2WAo3i",
        "outputId": "ae16d719-7462-44b2-81f3-e4c8b977ae84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['titanic_svc_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_pipeline = joblib.load('titanic_svc_model.joblib')\n",
        "\n",
        "# Load the new data for prediction\n",
        "new_data = pd.read_csv('/content/titanic_test.csv')  # Replace 'new_data.csv' with the actual filename\n",
        "\n",
        "# Make predictions using the loaded pipeline\n",
        "new_data_predictions = loaded_pipeline.predict(new_data)\n",
        "\n",
        "# Create a DataFrame to store predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'PassengerId': new_data['PassengerId'],\n",
        "    'Survived_Predicted': new_data_predictions\n",
        "})\n",
        "\n",
        "# Display the DataFrame with predictions\n",
        "print(\"Predictions for New Data:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QERuyGJ2ArzI",
        "outputId": "80743e67-9f4a-4a24-9505-db4fcd206226"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for New Data:\n",
            "     PassengerId  Survived_Predicted\n",
            "0            892                   0\n",
            "1            893                   0\n",
            "2            894                   0\n",
            "3            895                   0\n",
            "4            896                   0\n",
            "..           ...                 ...\n",
            "413         1305                   0\n",
            "414         1306                   1\n",
            "415         1307                   0\n",
            "416         1308                   0\n",
            "417         1309                   0\n",
            "\n",
            "[418 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}